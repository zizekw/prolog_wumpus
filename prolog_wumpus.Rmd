---
title: "SCS 3547 - Intelligent Agents & Reinforcement Learning"
author: "Bill Zizek"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

# Assignment 2 

## Objective

Take a copy of the WumpusWorld solution found [here](https://github.com/rlegendi/wumpus-prolog/blob/master/wumpus.pl). This code can be run [here](https://swish.swi-prolog.org/).

Write an explanation of how each **rule** in the `Prolog` program works. Rule headers in `Prolog` can be identified by looking for `:-`. For example:

```{r prolog example}
father(X,Y) :- parent(X,Y), male(X).
```

We can show X is the father of Y **if** X is a parent of Y **and** male.

Further syntax explanations available online in Prolog books/tutorials. 

## Explanations
### *Code chunks will be displayed, followed by the associated explanation*

```{r declaring dynamic methods}
:- dynamic ([
	     agent_location/1,
	     gold_location/1,
	     pit_location/1,
	     time_taken/1,
	     score/1,
	     visited/1,
	     visited_cells/1,
	     world_size/1,
	     wumpus_location/1,
             isPit/2,
             isWumpus/2,
             isGold/2
	    ]).
```

Here, we are declaring dynamic methods for various facets of WumpusWorld including locations, scores, world size, and more. Prolog has both static and dynamic procedures. An autonomous agent's strategy has been coded for in the dynamic WumpusWorld - so as such a static procedure which would never change would not be suitable. We are simply declaring identifiers within a dynamic method at this stage, so these identifiers will be defined below. The numbers included indicate how many arguments the identifier will take. 

Let's get started!

```{r start game}
start :-
    format('Initializing started...~n', []),
    init,
    format('Let the game begin!~n', []),
    take_steps([[1,1]]).
```

Here we can `start` the game (no arguments) **if** the predicate `format` printing some text is successful with an empty list **and** the `init` functor can be called to set up the WumpusWorld (more on this below) with no arguments necessary **and** the predicate `format` printing some text is successful with an empty list **and** a fact called `take_steps` to modulate location (more on this below) is called by supplying a list of lists to set us in the starting position 1,1.

```{r scheduling simulation}
step_pre(VisitedList) :-
    agent_location(AL),
    gold_location(GL),
    wumpus_location(WL),
    score(S),
    time_taken(T),

    ( AL=GL -> writeln('WON!'), format('Score: ~p,~n Time: ~p', [S,T])
    ; AL=WL -> format('Lost: Wumpus eats you!~n', []),
               format('Score: ~p,~n Time: ~p', [S,T])
    ; take_steps(VisitedList)
    ).

take_steps(VisitedList) :-
    make_percept_sentence(Perception),
    agent_location(AL),
    format('I\'m in ~p, seeing: ~p~n', [AL,Perception]),

    update_KB(Perception),
    ask_KB(VisitedList, Action),
    format('I\'m going to: ~p~n', [Action]),

    update_time,
    update_score,

    agent_location(Aloc),
    VL = [Aloc|VisitedList],
    standing,
    step_pre(VL).
```

First we define the rule `step_pre` using `VisitedList` wherein we check if the agent, gold, and wumpus location warrant an update of the game status (win/loss), to stop the game (elsewhere) and print the outcome to the console if no next move is required based on where the agent has been. The rule is that if the agent, gold, and wumpus locations (+ arguments) equal a set of defined conditions (such as agent location matching the gold location or wumpus location) - the predicate `format` will print some text contingent on the outcome alongside the matching score and time taken. If the agent is not at the gold or wumpus, the `;` is a disjunction operator in prologue so the agent will take more steps. This historical list of locations is what declares the end of the game. 

Now we define our `take_steps` rule again using the `VisitedList` argument. First the environment perception of neighboring nodes is made (we define this later - breeze, stench, and glitter). In addition to this perception, we bind this with the agent location and print it to the console so we know where the current location is and what's around. This perception is what an agent uses to make a decision of where to move next. We add this perception information to our knowledgebase tracking information about the wumpus, a pit, and if the move is permitted. Then we print where we're going to the console, update the time + score, update our visited list, update the standings, and take the step based on the `step_pre` rule we just defined!

```{r updating states}
update_time :-
    time_taken(T),
    NewTime is T+1,
    retractall( time_taken(_) ),
    assert( time_taken(NewTime) ).

update_score :-
    agent_location(AL),
    gold_location(GL),
    wumpus_location(WL),
    update_score(AL, GL, WL).

update_score(P) :-
    score(S),
    NewScore is S+P,
    retractall( score(_) ),
    assert( score(NewScore) ).

update_score(AL, AL, _) :-
    update_score(1000).

update_score(_,_,_) :-
    update_score(-1).

update_agent_location(NewAL) :-
    retractall( agent_location(_) ),
    assert( agent_location(NewAL) ).

is_pit(no,  X) :-
    \+ pit_location(X).
is_pit(yes, X) :-
    pit_location(X).
```

In this code chunk, we are updating a lot of states.

First, we can `update_time` if we take the `time_taken` and update a `NewTime` by coercing an addition function. Then `retractall` removes existing facts within `time_taken` before we then update with the `NewTime`.  

Here we can instantiate the `update_score` structure with no arguments if we can take the agent, gold, and wumpus location to compute update_score. 

Here we can further `update_score` by supplying the argument P if we can take S and coerce the computation of an addition for a `NewScore`. As described, we can then `retractall` and assert the `NewScore`.

We then `update_score`  few more times. Then we `update_agent_location` similar to how we updated the score.

Finally, we determine if X is not a pit if we show X **does not** (\+ is a negation) equal the pit location. Then to determine if X is a pit you do the opposite.

```{r display standings}
standing :-
    wumpus_location(WL),
    gold_location(GL),
    agent_location(AL),

    ( is_pit(yes, AL) -> format('Agent was fallen into a pit!~n', []),
      fail
    ; stnd(AL, GL, WL)
      %\+ pit_location(yes, Al),
    ).

stnd(_, _, _) :-
    format('There\'s still something to do...~n', []).

stnd(AL, _, AL) :-
    format('YIKES! You\'re eaten by the wumpus!', []),
    fail.

stnd(AL, AL, _) :-
    format('AGENT FOUND THE GOLD!!', []),
    true.
```

We are simply displaying the standings here.

First, we can instantiate the standings if we can obtain the wumpus, gold, and agent location. We defined `is_pit` and if the answer is yes then the standings are updating and we render some text to the console communicating as such. The game is over. Otherwise if it is infact not a pit, then we present the standings and carry on. The structure for `stnd` can hold 3 arguments for the agent, wumpus, and gold location respectively. A single underscore denotes any term for an argument. Next we define some standings updates that if based on the agent location there's nothing exciting that we have to carry on. Similarly if we find the wumpus, it's game over and we render text to the console as such. Finally, if we find the gold then we win. 

```{r perception}
make_perception([_Stench,_Bleeze,_Glitter]) :-
    agent_location(AL),
    isStinky(AL),
    isBleezie(AL),
    isGlittering(AL).

test_perception :-
	make_percept_sentence(Percept),
	format('I feel ~p, ',[Percept]).

make_percept_sentence([Stench,Bleeze,Glitter]) :-
	smelly(Stench),
	bleezy(Bleeze),
	glittering(Glitter).
```

This chunk is all about perception.

First, we can `make_perception`if we have the agent location and then based on that can tell if it's stinky (wumpus!!), if it's breezy (pit nearby!!), or if there's glittering (gold!!). All of these perceptions are critical to decision making to optimize winning over losing.

Then, we can `test_perception` if we take the perception sentence we are about to define below and render an appropriate sentence to the console.

Finally, we can make an appropriate perception sentence respectively using a list of perception arguments to indicate the wumpus, a pit, or gold.

```{r initializing}
init :-
    init_game,
    init_land_fig72,
    init_agent,
    init_wumpus.

init_game :-
    retractall( time_taken(_) ),
    assert( time_taken(0) ),

    retractall( score(_) ),
    assert( score(0) ),

    retractall( visited(_) ),
    assert( visited(1) ),

    retractall( isWumpus(_,_) ),
    retractall( isGold(_,_) ),

    retractall( visited_cells(_) ),
    assert( visited_cells([]) ).

init_land_fig72 :-
    retractall( world_size(_) ),
    assert( world_size(4) ),

    retractall( gold_location(_) ),
    assert( gold_location([3,2]) ),

    retractall( pit_location(_) ),
    assert( pit_location([4,4]) ),
    assert( pit_location([3,3]) ),
    assert( pit_location([1,3]) ).

init_agent :-
    retractall( agent_location(_) ),
    assert( agent_location([1,1]) ),

    visit([1,1]).

init_wumpus :-
    retractall( wumpus_location(_) ),
    assert( wumpus_location([4,1]) ).

visit(Xs) :-
    visited_cells(Ys),
    retractall( visited_cells(_) ),
    assert( visited_cells([Ys|Xs]) ).
```

This chunk is all about initializing the environment.

We can `init` if we can successfully `init_game`, `init_land_fig72`, `init_agent`, and `init_wumpus.`

We `init_game` by wiping all environment variables. We retract existing time, score, visited locations, and game end-points. Then we `assert` a respective starting value.

We are configuring the board a bit here. We can `init_land_fig72` if we can `retractall` and set the `world_size`. Similarly as described, we wipe and set the gold location and pit locations.

As described above, we can `init_agent` if we `retractall` on the location of the agent and then assert the location as the starting point [1,1].
 
As above, we `init_wumpus` similar to the agent by `retractall` the location and asserting the starting point [4,1].

We can record the visited places by supplying the X values of the grid if we also supply the visited Y values of the grid and then wipe the visited location and then asserting the visited cells for the Y and X values. 

```{r Perceptors}
%%% Institiation error!!!

%adj(X,Y) :-
%    world_size(WS),
%    ( X is Y+1, Y   < WS
%    ; X is Y-1, Y-1 > 0
%    ).

adj(1,2).
adj(2,1).
adj(2,3).
adj(3,2).
adj(3,4).
adj(4,3).

adjacent( [X1, Y1], [X2, Y2] ) :-
    ( X1 = X2, adj( Y1, Y2 )
    ; Y1 = Y2, adj( X1, X2 )
    ).

%adjacent([X1,Y],[X2,Y]) :-
%    adj(X1,X2).

%adjacent([X,Y1],[X,Y2]) :-
%    adj(Y1,Y2).

isSmelly(Ls1) :-
    wumpus_location( Ls2 ),
    adjacent( Ls1, Ls2 ).

isBleezy(Ls1) :-
    pit_location( Ls2 ),
    adjacent( Ls1, Ls2 ).

isGlittering( [X1, Y1] ) :-
    gold_location( [X2, Y2] ),
    X1 = X2,
    Y1 = Y2.

bleezy(yes) :-
    agent_location(AL),
    isBleezy(AL).
bleezy(no).

smelly(yes) :-
    agent_location(AL),
    isSmelly(AL).
smelly(no).

glittering(yes) :-
    agent_location(AL),
    isGlittering(AL).
glittering(no).
```

This code chunk is all about the agent's perceptions of the environment around.

`%` indicates a comment in Prolog so we have some commented out code chunks to begin with.

Next we are stating several facts using `adj(_,_)`. What we are defining here is that two integers (of either X or Y dimension) are adjacent to each other. 

Then, we define a rule where given [X1, Y1] and [X2, Y2], they are `adjacent` if we can show they are on the same column + their Y's are `adj` *or* that they are on the same row + and their X's are `adj`.

Next we are perceiving if the wumpus is nearby by `isSmelly` if we supply `Ls1` and can show the wumpus location `Ls2` is adjacent. 

We next do the same as above for a pit judging if it `isBleezy` (likely a typo for breezy).

The previous two rules were different in that we are perceiving something adjacent to the location. For glittering, this is only perceived if gold is **in** the square. Therefore, we can show `isGlittering` by supplying [X1,Y1] with the gold location [X2,Y2] and equating the locations to each other. 

We finish off this code chunk by supplying yes/no logic for each perception. Essentially we can render `yes` for a perceiption if we can show that the agent location corresponds with the conditions for the perceptions of scent, breeze, and glitter.

```{r knowledge base}
update_KB( [Stench,Bleeze,Glitter] ) :-
    add_wumpus_KB(Stench),
    add_pit_KB(Bleeze),
    add_gold_KB(Glitter).

% if it would be 'yes' -> it would mean the player is eaten ;]
add_wumpus_KB(no) :-
    %agent_location(L1),
    %adjacent(L1, L2),
    %assume_wumpus(no, L2).
    agent_location([X,Y]),
    world_size(_),

    % Checking needed!!
    % adj will freeze for (4,_) !!

    Z1 is Y+1, assume_wumpus(no,[X,Z1]),
    Z2 is Y-1, assume_wumpus(no,[X,Z2]),
    Z3 is X+1, assume_wumpus(no,[Z3,Y]),
    Z4 is X-1, assume_wumpus(no,[Z4,Y]).

add_pit_KB(no) :-
    agent_location([X,Y]),
    Z1 is Y+1, assume_pit(no,[X,Z1]),
    Z2 is Y-1, assume_pit(no,[X,Z2]),
    Z3 is X+1, assume_pit(no,[Z3,Y]),
    Z4 is X-1, assume_pit(no,[Z4,Y]).

% Checking needed!! If its not already in the KB !!!
add_pit_KB(yes) :-
    agent_location([X,Y]),
    Z1 is Y+1, assume_pit(yes,[X,Z1]),
    Z2 is Y-1, assume_pit(yes,[X,Z2]),
    Z3 is X+1, assume_pit(yes,[Z3,Y]),
    Z4 is X-1, assume_pit(yes,[Z4,Y]).

add_gold_KB(no) :-
    gold_location(GL),
    assume_gold(no, GL).

add_gold_KB(yes) :-
    gold_location([X1,Y1]),
    agent_location([X2,Y2]),
    X1 = X2, Y1 = Y2,
    assume_gold(yes, [X1,Y1]).

assume_wumpus(no, L) :-
    retractall( isWumpus(_, L) ),
    assert( isWumpus(no, L) ),
    format('KB learn ~p - no Wumpus there!~n', [L]).

assume_wumpus(yes, L) :-
    %wumpus_healthy, % Will be included ...
    retractall( isWumpus(_, L) ),
    assert( isWumpus(yes, L) ),
    format('KB learn ~p - possibly the Wumpus is there!~n', [L]).

assume_pit(no, L) :-
    retractall( isPit(_, L) ),
    assert( isPit(no, L) ),
    format('KB learn ~p - there\'s no Pit there!~n', [L]).

assume_pit(yes, L) :-
    retractall( isPit(_, L) ),
    assert( isPit(yes, L) ),
    format('KB learn ~p - its a Pit!~n', [L]).

assume_gold(no, L) :-
    retractall( isGold(_, L) ),
    assert( isGold(no, L) ),
    format('KB learn ~p - there\'s no gold here!~n', [L]).

assume_gold(yes, L) :-
    retractall( isGold(_, L) ),
    assert( isGold(yes, L) ),
    format('KB learn ~p - GOT THE GOLD!!!~n', [L]).

permitted([X,Y]) :-
    world_size(WS),
    0 < X, X < WS+1,
    0 < Y, Y < WS+1.

ask_KB(VisitedList, Action) :-
    isWumpus(no, L),
    isPit(no, L),
    permitted(L),
    not_member(L, VisitedList),
    update_agent_location(L),
    Action = L.
```

Finally, we come to define our knowledge base (KB) for the Wumpus World. We are building up our KB to make appropriate decisions.

We begin with a general `update_KB` rule to update if there is a relevant outcome pertaining to the wumpus, a pit, or the gold. This will be further defined in subsequent rules when there is a pertinent update to add to the agent's KB.

`add_wumpus_KB` with the argument `no` is the case if it is proven that the agent location [X,Y] is not the wumpus +/- 1 space across the agent's current X,Y dimensions. We will define `assume_wumpus` rule below.

Similarly, we do not `add_pit_KB` from supplying the `agent_location`'s [X,Y] +/- across X and Y and the return from `assume_pit` comes back as `no`. We define `assume_pit` below. In contrast, we define do `add_pit_KB` if `yes` is returned by `assume_pit` similarly checking +/- across X and Y from the agents location. 

We `add_gold_KB` if we can show the [X,Y] location of the gold is equivalent to that of the agents location. In that case, we `assume_gold`.

We will now define a few `assume_` rules to supplement growing our KB. These rules are intended to assert a perception of the environment and render the situation to the console. We `assume_wumpus` if we supply `no` and the location `L` and then print that the knowledge base has learned there is no wumpus! 

We repeat the above `assume_` rules for yes/no for the wumpus, the pit, and gold. Simiarly in each case, we are helping grow our KB alongside the `add_<variable>_KB` rules we defined earlier.

We define if a move is `permitted` by supplying the [X,Y] and showing that the X/Y values are greater than 0 and less than the world size `WS` + 1. 

Finally, we define the rule for `ask_KB` where we supply the `VisitedList` and `Action` if we can ask the knowledgebase if there is a wumpus/pit in a certain location and if the move is permitted then we update the agent location with the provided action.

```{r utils}
not_member(_, []).
not_member([X,Y], [[U,V]|Ys]) :-
    ( X=U,Y=V -> fail
    ; not_member([X,Y], Ys)
    ).
```

# TODO